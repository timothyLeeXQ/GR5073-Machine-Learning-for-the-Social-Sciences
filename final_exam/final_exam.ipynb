{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2534,
     "status": "ok",
     "timestamp": 1588749086207,
     "user": {
      "displayName": "timothy lee",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCY2uRGVjIrnN9B2gCMbB4nKNNF0hnKbarpShwKw=s64",
      "userId": "05402697373745650248"
     },
     "user_tz": -480
    },
    "id": "SmnvJ6YWu5dZ",
    "outputId": "a444bed8-e684-4103-96a4-b2cf267aaf58"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cjEn4ctztxpO"
   },
   "source": [
    "In answering each of the following questions please include a) the question as a markdown header in your Jupyter notebook, b)  the raw code that you used to generate any results, tables, or figures, and c) the top ten or fewer rows of the dataframe (do not include more than ten rows for any table in your report)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K6npyGXVt3Pe"
   },
   "source": [
    "# 1.  From the perspective of a social scientist, which models did we learn this semester that are useful for ruling out alternative explanations through control variables AND that allow us to observe substantively meaningful information from model coefficients?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eM9jIJc3vWTG"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "* (Multiple) Linear Regression/OLS Regression - Continuous outcome variable\n",
    "* Logistic Regression - Categorical outcome variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mslthYeFt8Be"
   },
   "source": [
    "\n",
    "# 2. Describe the main differences between supervised and unsupervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FqUZjw_wvVvn"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "Supervised Learning | Unsupervised Learning\n",
    "---|---\n",
    "Clearly defined outcome variable|No outcome variable\n",
    "Interested in predicting the outcome variable|Interested in discovering information about data without reference to an outcome variable\n",
    "Clearly defined, quantifiable evaluation metrics like accuracy|Usually subjective evaluation of success\n",
    "May be supported by unsupervised techniques|May support supervised techniques\n",
    "Not conventionally used for data exploration | Often used for data exploration through visualisation of PCA dimensions or clustering\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SpK8glI6t8Qs"
   },
   "source": [
    "\n",
    "# 3. Is supervised or unsupervised learning the primary approach that is used by machine learning practitioners?  For whatever approach you think is secondary, why would you use this approach (what's a good reason to use these kinds of models?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PhjQum5VvVLW"
   },
   "source": [
    "---\n",
    "Supervised Learning is the primary approach used by machine learning practitioners\n",
    "\n",
    "Unsupervised learning can be used for data exploration to discover patterns in the data. For instance,\n",
    "* Visualising of data with more than 2 dimensions on a 2D surface after transformation using PCA\n",
    "* Discovering and understanding groups in a dataset through clustering\n",
    "\n",
    "Unsupervised learning can also be used to support supervised learning.\n",
    "* By helping the practitioner understand the data better\n",
    "* Through dimensionality reduction (with unsupervised techniques like PCA or manifold learning algorithms) to reduce the dimensionality of the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n5NzgqtcuCUd"
   },
   "source": [
    "# 4. Which unsupervised learning modeling approaches did we cover this semester?  What are the major differences between these techniques?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CRF6tRvCvUPU"
   },
   "source": [
    "\n",
    "---\n",
    "### Differences between Clustering and Dimensionality Reduction Techniques\n",
    "Dimensionality reduction | Clustering\n",
    "--- | ---\n",
    "Captures patterns to produce a lower dimensional representation of the data | Groups data points into \"clusters\", often based on proximity\n",
    "May involve transforming the data to be represented on new axes|Does not involve transforming data onto a new set of axes\n",
    "Does not assign observations to groups as output|Assigns observations to groups as output\n",
    "\n",
    "### Differences between Clustering Techniques\n",
    "K-means clustering|Hierarchical/Agglomerative Clustering\n",
    "---|---\n",
    "Initial clusters are formed by partitioning observations into a pre-specified number of clusters|Initial clusters are defined by having each observation as its own cluster\n",
    "Points are reassigned to clusters depending on proximity to the cluster centroid| Clusters are expanded by joining the two closest clusters together at each step\n",
    "Cluster assignment relies on point-to-cluster centroid distance|Cluster agglomeration depends on inter-cluster distance, can use pairwise dissimilarities between cluster points instead of point-to-cluster centroid distance\n",
    "Clustering process cannot be visualised in a dendrogram|Cluster formation can be visualised using a dendrogram\n",
    "Number of clusters must be pre-defined|Number of clusters can (at least theoretically) be determined post-clustering with the aid of a dendrogram by defining a cut-point\n",
    "\n",
    "### Differences between Dimensionality Reduction Techniques\n",
    "PCA|Manifold Learning\n",
    "---|---\n",
    "Based on preserving the maximal variance between points in the data|Based on preserving pairwise distances between points in the data\n",
    "Captures only linear patterns in the data|Can capture non-linear patterns in the data\n",
    "Intrinsically filters noise from important components (assuming more signal than noise in the pattern of variation in the data)|Susceptible to noise in the data causing drastic changes in the output\n",
    "Proportion of explained variance is a useful metric for optimal number of output dimensions from dimensionality reduction|Difficult to determine optimal number of output dimensions\n",
    "Works well in theory and practice|Impressive with some toy datasets, but often struggles with real world data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "thoacG7ruC6F"
   },
   "source": [
    "# 5.  What are the main benefits of using Principal Components Analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "20D9EgqfvT0d"
   },
   "source": [
    "---\n",
    "### PCA for dimensionality reduction\n",
    "Data with high-dimensionality often take longer to train, and require more observations to achieve acceptable accuracy. PCA can be used to reduce the number of dimensions in the data while preserving an acceptable proportion of the variation in the original data. Using data that has been transformed from a higher-dimensional space into a lower-dimensional space using PCA may yield superior results on sparser datasets and decrease model training times.\n",
    "\n",
    "\n",
    "### PCA for data visualisation\n",
    "\n",
    "PCA can be used to visualise data that exist in a high-dimensional space. As visualisation tools are often constrained to 2D, 3D and at most 4D) representations, data often exist in a space with many more dimensions. PCA can preserve as much variation of the data within these dimensions as possible in 2 principal components. Plotting the data along these principal components allows the viewer to understand most of the distribution of the data across all its dimensions in a 2-dimensional presentation format.\n",
    "\n",
    "### PCA over Manifold Learning Techniques\n",
    "* PCA often works better in practice\n",
    "* PCA naturally filters noise from important components (assuming more signal than noise in the pattern of variation in the data), whereas manifold learning algorithms are susceptible to noise in the data causing drastic changes in the output\n",
    "* With PCA you can use the proportion of explained variance you want to preserve to select the number of components to keep. Determining the number of output dimensions for manifold learning is not as easily defined.\n",
    "* PCA has straightforward approaches to dealing with missing data, but manifold learning algorithms do not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E4GnzNctuC8f"
   },
   "source": [
    "# 6. Thinking about neural networks, what are three major differences between a deep multilayer perceptron network and a convolutional neural network model?\n",
    "\n",
    "Be sure to define any key terms in your explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BXpxM2BQvTSH"
   },
   "source": [
    "---\n",
    "### Presence of Convolutional Layers\n",
    "\n",
    "* Convolutional neural networks use convolutional layers, whereas multilayer perceptron networks do not.\n",
    "* Convolutional layers preserve the original dimensionality of the input data - for instance, as a 28\\*28 matrix, instead of flattening the data out into a long column vector - like from a 28\\*28 matrix into a column vector with 784 elements - as is done with fully connected layers.\n",
    "  - While fully connected layers are used in both convolutional neural networks and multilayer perceptron networks, convolutional layers are not used in multilayer perceptron networks, but are used in convolutional neural networks.\n",
    "* Convolutional layers involve the application of a filter layer that is smaller than the input matrix that is convolved over the input matrix. The filter is overlaid with the corner of the input matrix, taking element-wise multiplications of the filter values with the input matrix to yield a single value as output. This is repeated as the filter is moved (convolved) over the entire input matrix, with the resultant output vectors forming the output of the convolutional layer.\n",
    "\n",
    "### Use of Pooling\n",
    "\n",
    "* Convolutional neural networks use pooling layers, whereas multilayer perceptron networks do not.\n",
    "* Pooling layers serve to aggregate the output from convolutional layers to reduce the output dimensions. As convolutional layers are not present in multilayer perceptron networks, these layers are not used with multilayer perceptron networks.\n",
    "* A pooling layer is defined that is smaller than the input matrix. Like a filter, it is convolved over the input matrix as described above.\n",
    "  - The resultant output may either be the maximum value of the input matrix that is overlaid by the pooling layer (max pooling) or the average value of the input matrix that is overlaid by the pooling layer (average pooling)\n",
    "\n",
    "### Padding\n",
    "\n",
    "* Convolutional neural networks may add to the dimensions of the input via padding. This is not done with multilayer perceptron networks.\n",
    "* Padding refers to increasing the dimensionality of an input matrix by adding elements with a value of 0 around the edges of the original input matrix.\n",
    "  - For instance, a 3\\*3 input matrix can be turned into a 5\\*5 input matrix by adding a single ring of zeroes around the original 3\\*3 matrix.\n",
    "* Padding is usually used together with convolutional layers\n",
    "  - So control the output matrix dimensions from a convolutional layer\n",
    "  - To enable flexibility in choosing the filter size and stride length in a convolutional layer\n",
    "  - To enable each filter value to be overlaid across all the input matrix values at least once\n",
    "* There is little need for padding in fully connected layers that are the only type of layer in a multilayer perceptron network, as fully connected layers do not use a convolving filter. Additional 0 values are not traditionally added as input into a fully connected layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7YU5UWdHuC_U"
   },
   "source": [
    "# 7. Write the keras code for a multilayer perceptron neural network with the following structure:\n",
    "\n",
    "* Three hidden layers.\n",
    "* 50 hidden units in the first hidden layer\n",
    "* 100 in the second, and\n",
    "* 150 in the third.\n",
    "* Activate all hidden layers with relu.\n",
    "* The output layer should be built to classify to five categories.\n",
    "* Further, your optimization technique should be stochastic gradient descent.\n",
    "\n",
    "(This code should simply build the architecture of the model.  You will not run it on real data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2505,
     "status": "ok",
     "timestamp": 1588749086210,
     "user": {
      "displayName": "timothy lee",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCY2uRGVjIrnN9B2gCMbB4nKNNF0hnKbarpShwKw=s64",
      "userId": "05402697373745650248"
     },
     "user_tz": -480
    },
    "id": "OHs3s7zxvSsb",
    "outputId": "d167336c-8107-4f1f-ffa5-573d2d11b7e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 150)               15150     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 755       \n",
      "=================================================================\n",
      "Total params: 26,055\n",
      "Trainable params: 26,055\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sgd = SGD(lr=0.01)\n",
    "\n",
    "model_7 = Sequential()\n",
    "model_7.add(Dense(50, activation = 'relu', input_dim = 100))\n",
    "model_7.add(Dense(100, activation = 'relu'))\n",
    "model_7.add(Dense(150, activation = 'relu'))\n",
    "model_7.add(Dense(5, activation = 'softmax'))\n",
    "model_7.compile(optimizer = sgd,\n",
    "                loss = 'categorical_crossentropy',\n",
    "                metrics = ['accuracy'])\n",
    "\n",
    "model_7.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R5baESLluDBk"
   },
   "source": [
    "# 8. Write the keras code for a multilayer perceptron neural network with the following structure:\n",
    "\n",
    "* Two hidden layers.\n",
    "* 75 hidden units in the first hidden layer and \n",
    "* 150 in the second. \n",
    "* Activate all hidden layers with relu. \n",
    "* The output layer should be built to classify a binary dependent variable.  \n",
    "* Further, your optimization technique should be stochastic gradient descent.  \n",
    "\n",
    "(This code should simply build the architecture of the model.  You will not run it on real data.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2476,
     "status": "ok",
     "timestamp": 1588749086213,
     "user": {
      "displayName": "timothy lee",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCY2uRGVjIrnN9B2gCMbB4nKNNF0hnKbarpShwKw=s64",
      "userId": "05402697373745650248"
     },
     "user_tz": -480
    },
    "id": "OZz_kmTyvSHe",
    "outputId": "f592ecfc-9e93-42ba-9e31-b8b9c43b00f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 75)                7575      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 150)               11400     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 19,126\n",
      "Trainable params: 19,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sgd = SGD(lr=0.01)\n",
    "\n",
    "model_8 = Sequential()\n",
    "model_8.add(Dense(75, activation = 'relu', input_dim = 100))\n",
    "model_8.add(Dense(150, activation = 'relu'))\n",
    "model_8.add(Dense(1, activation = 'sigmoid'))\n",
    "model_8.compile(optimizer = sgd,\n",
    "                loss = 'binary_crossentropy',\n",
    "                metrics = ['accuracy'])\n",
    "\n",
    "model_8.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fKLAC4dFuDEX"
   },
   "source": [
    "# 9.  Write the keras code for a convolutional neural network with the following structure: \n",
    "\n",
    "* Two convolutional layers.\n",
    "* 16 filters in the first layer and\n",
    "* 28 in the second. \n",
    "* Activate all convolutional layers with relu. \n",
    "* Use max pooling after each convolutional layer with a 2 by 2 filter. \n",
    "* The output layer should be built to classify to ten categories. \n",
    "* Further, your optimization technique should be stochastic gradient descent.  \n",
    "\n",
    "(This code should simply build the architecture of the model.  You will not run it on real data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2452,
     "status": "ok",
     "timestamp": 1588749086216,
     "user": {
      "displayName": "timothy lee",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCY2uRGVjIrnN9B2gCMbB4nKNNF0hnKbarpShwKw=s64",
      "userId": "05402697373745650248"
     },
     "user_tz": -480
    },
    "id": "DqyF22qsvRjA",
    "outputId": "fc892790-3b19-43d3-bcd0-bbe4773e7441"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 127, 127, 16)      208       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 127, 127, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 62, 62, 28)        1820      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 62, 62, 28)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 31, 31, 28)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 26908)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                269090    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 271,118\n",
      "Trainable params: 271,118\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model_9 = Sequential()\n",
    "# Conv Layer 1\n",
    "model_9.add(Conv2D(filters = 16, kernel_size = (2, 2), padding='valid', \n",
    "                 data_format=\"channels_last\", input_shape = (128, 128, 3)))\n",
    "model_9.add(Activation('relu'))\n",
    "model_9.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Conv Layer 2\n",
    "model_9.add(Conv2D(filters = 28, kernel_size = (2, 2), padding='valid')) \n",
    "model_9.add(Activation('relu'))\n",
    "model_9.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Fully Connected Output\n",
    "model_9.add(Flatten())\n",
    "model_9.add(Dense(10))\n",
    "model_9.add(Activation('softmax'))\n",
    "model_9.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_9.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7CpTPYkuDHP"
   },
   "source": [
    "# 10.  Write the keras code for a convolutional neural network with the following structure: \n",
    "\n",
    "* Two convolutional layers. \n",
    "* 32 filters in the first layer and \n",
    "* 32 in the second. \n",
    "* Activate all convolutional layers with relu. \n",
    "* Use max pooling after each convolutional layer with a 2 by 2 filter. \n",
    "* Add two fully connected layers with 128 hidden units in each layer and relu activations. \n",
    "* The output layer should be built to classify to six categories. \n",
    "* Further, your optimization technique should be stochastic gradient descent.  \n",
    "\n",
    "(This code should simply build the architecture of the model.  You will not run it on real data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2796,
     "status": "ok",
     "timestamp": 1588749086585,
     "user": {
      "displayName": "timothy lee",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCY2uRGVjIrnN9B2gCMbB4nKNNF0hnKbarpShwKw=s64",
      "userId": "05402697373745650248"
     },
     "user_tz": -480
    },
    "id": "91zGH-wqtZ-A",
    "outputId": "f1dedcb1-7fbc-46f8-ecef-2414672e912d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 127, 127, 32)      416       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 62, 62, 32)        4128      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 30752)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               3936384   \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 6)                 774       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 3,958,214\n",
      "Trainable params: 3,958,214\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model_10 = Sequential()\n",
    "# Conv Layer 1\n",
    "model_10.add(Conv2D(filters = 32, kernel_size = (2, 2), padding='valid', \n",
    "                 data_format=\"channels_last\", input_shape = (128, 128, 3)))\n",
    "model_10.add(Activation('relu'))\n",
    "model_10.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Conv Layer 2\n",
    "model_10.add(Conv2D(filters = 32, kernel_size = (2, 2), padding='valid')) \n",
    "model_10.add(Activation('relu'))\n",
    "model_10.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Fully Connected 1\n",
    "model_10.add(Flatten())\n",
    "model_10.add(Dense(128))\n",
    "model_10.add(Activation('relu'))\n",
    "# Fully Connected 2\n",
    "model_10.add(Dense(128))\n",
    "model_10.add(Activation('relu'))\n",
    "# Fully Connected Output\n",
    "model_10.add(Dense(6))\n",
    "model_10.add(Activation('softmax'))\n",
    "model_10.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_10.summary()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOaEFl4Y/deBy2rUZY7qfsR",
   "collapsed_sections": [],
   "name": "final_exam.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
